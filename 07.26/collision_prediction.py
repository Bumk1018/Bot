# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S18XWJxFwYw4fYlzUaNoswr-JTbONmKI
"""

# YOLO + Optical Flow + 충돌 시각화 + 반응시간 기준 적용 + 자동 다운로드

import cv2
import numpy as np
import logging
import os
import subprocess
import sys
import urllib.request
import zipfile
import platform

from ultralytics import YOLO

# === 패키지 자동 설치 ===
import pkg_resources
required = {'yt-dlp', 'ultralytics', 'opencv-python', 'numpy'}
installed = {pkg.key for pkg in pkg_resources.working_set}
missing = required - installed
if missing:
    print(f"[설치] 누락된 패키지 설치 중: {missing}")
    try:
        subprocess.check_call([sys.executable, '-m', 'pip', 'install', *missing])
    except subprocess.CalledProcessError:
        print("[오류] 패키지 설치 실패. 수동 설치 필요.")

# === 설정 ===
VIDEO_URL = 'https://www.youtube.com/watch?v=CRJViZBrOlI'
VIDEO_FILE = 'accident.mp4'
YOLO_MODEL = 'yolov8n.pt'
FPS = 30
METER_PER_PIXEL = 0.05
COLLISION_THRESHOLD = 3.0       # 운전자 반응 불가능한 충돌 시간 (초)
MIN_APPROACH_SPEED = 5.0        # 최소 상대 접근 속도 (m/s)
MAX_COLLISION_DISTANCE = 20.0   # 최대 충돌 감지 거리 (m)
OUTPUT_FOLDER = 'collision_frames'

# === 로깅 ===
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler("collision_log.txt"),
        logging.StreamHandler()
    ]
)

class TrackedObject:
    def __init__(self, track_id, centroid, timestamp):
        self.id = track_id
        self.positions = [(centroid, timestamp)]
        self.speeds = []

    def update(self, centroid, timestamp):
        self.positions.append((centroid, timestamp))
        if len(self.positions) >= 2:
            (x1, y1), t1 = self.positions[-2]
            (x2, y2), t2 = self.positions[-1]
            dist = np.linalg.norm([x2 - x1, y2 - y1]) * METER_PER_PIXEL
            dt = t2 - t1
            if dt > 0:
                self.speeds.append(dist / dt)

    def last_position(self):
        return self.positions[-1][0]

    def last_speed(self):
        return self.speeds[-1] if self.speeds else 0.0

def compensate_camera_motion(prev_gray, gray):
    flow = cv2.calcOpticalFlowFarneback(prev_gray, gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)
    dx = np.median(flow[..., 0])
    dy = np.median(flow[..., 1])
    return dx, dy

def predict_collision(objs, frame, frame_idx):
    if 0 not in objs:
        return  # 블랙박스 차량이 없으면 스킵
    bb_car = objs[0]  # 블랙박스 차량 기준
    for tid, obj in objs.items():
        if tid == 0 or len(obj.positions) < 2 or len(bb_car.positions) < 2:
            continue

        p1 = np.array(bb_car.last_position())
        p2 = np.array(obj.last_position())
        direction_vector = p2 - p1
        angle = np.degrees(np.arctan2(direction_vector[1], direction_vector[0])) % 360

        # 충돌 판정은 차량이 정면 90도 이내에 있을 때만
        if not (315 <= angle or angle <= 45):
            continue

        dist = np.linalg.norm(p1 - p2) * METER_PER_PIXEL
        v_rel = abs(bb_car.last_speed() - obj.last_speed())
        if v_rel > MIN_APPROACH_SPEED and dist < MAX_COLLISION_DISTANCE:
            t_coll = dist / v_rel
            if t_coll < COLLISION_THRESHOLD:
                msg = f"[⚠️ 운전자 반응 불가 충돌 예상] ID 0 vs {tid} | 거리={dist:.2f}m | Δv={v_rel:.2f}m/s | 충돌까지 {t_coll:.2f}s"
                logging.warning(msg)
                os.makedirs(OUTPUT_FOLDER, exist_ok=True)
                save_path = os.path.join(OUTPUT_FOLDER, f"frame_{frame_idx:04d}.jpg")
                cv2.imwrite(save_path, frame)
                cv2.arrowedLine(frame, tuple(p1), tuple(p2), (0, 0, 255), 2)
                cv2.putText(frame, "Collision Risk!", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

def download_video(url, output):
    if not os.path.exists(output):
        logging.info(f"[다운로드] {url} → {output}")
        try:
            subprocess.run(['yt-dlp', '-o', output, url], check=True)
        except Exception as e:
            logging.error(f"[다운로드 실패] {e}")
    else:
        logging.info(f"[이미 존재] {output}")

def main():
    download_video(VIDEO_URL, VIDEO_FILE)

    model = YOLO(YOLO_MODEL)
    cap = cv2.VideoCapture(VIDEO_FILE)

    if not cap.isOpened():
        logging.error("영상 열기 실패")
        return

    ret, prev_frame = cap.read()
    if not ret:
        logging.error("첫 프레임 읽기 실패")
        return

    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
    tracked = {}
    next_id = 0
    frame_idx = 1

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        dx, dy = compensate_camera_motion(prev_gray, gray)
        timestamp = frame_idx / FPS

        results = model.predict(frame, conf=0.4, verbose=False)[0]
        centers = []
        for box in results.boxes:
            if int(box.cls[0]) != 2:
                continue
            x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
            cx, cy = int((x1 + x2) / 2 - dx), int((y1 + y2) / 2 - dy)
            centers.append((cx, cy))

        assigned = set()
        for cx, cy in centers:
            matched = False
            for tid, obj in tracked.items():
                last_pos = obj.last_position()
                if np.linalg.norm(np.array([cx, cy]) - np.array(last_pos)) < 50:
                    obj.update((cx, cy), timestamp)
                    assigned.add(tid)
                    matched = True
                    break
            if not matched:
                tracked[next_id] = TrackedObject(next_id, (cx, cy), timestamp)
                assigned.add(next_id)
                next_id += 1

        for tid in tracked:
            if tid in assigned:
                pos = tracked[tid].last_position()
                spd = tracked[tid].last_speed()
                cv2.circle(frame, pos, 4, (0, 255, 0), -1)
                cv2.putText(frame, f"ID{tid} {spd:.1f}m/s", (pos[0]-25, pos[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 1)

        predict_collision(tracked, frame, frame_idx)
        cv2.imshow("YOLO Tracking", frame)
        if cv2.waitKey(1) == 27:
            break

        prev_gray = gray.copy()
        frame_idx += 1

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()